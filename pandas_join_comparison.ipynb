{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study of Full Outer Joins in *pandas*\n",
    "*Eric Nordstrom* | *eanord4@gmail.com*  \n",
    "*December 15th, 2019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Objective\n",
    "\n",
    "I recently found that, in addition to the standard *pd.merge* and *pd.DataFrame.merge* functions, *pandas* provides at least one other way to perform a full outer join, which is to create a *pd.DataFrame* instance and feed it *pd.Series* instances as data (see **Introduction**).\n",
    "\n",
    "This experiment aims to determine the relative speed and scaling between these three ways of joining with *pandas*. The experiment also aims to find how null values affect the speed of joining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Introduction\n",
    "\n",
    "The *pandas* Python module has at least the following three ways of performing joins between datasets.\n",
    "\n",
    "1. ***pandas.merge*** is a function taking inputs of two *pandas.DataFrame* instances (datasets) in addition to parameters specifying the type of join, the column(s) on which to join, etc.\n",
    "\n",
    "2. ***pandas.DataFrame.merge*** is a method of the *pandas.DataFrame* class which considers the instance whose *merge* method was called as the **left** dataset and an input data frame as the **right** dataset. Additional parameters are used similarly to *pandas.merge*. This method likely works in the same way as *pandas.merge*, but this was not confirmed before the experiment.\n",
    "\n",
    "3. Creating a new data frame by calling the ***pandas.DataFrame*** class (thereby calling its *\\__new\\__* method) also performs a full outer join if *pandas.Series* instances are provided as columns. The join in this case is assumed to be on the indices of the series provided as illustrated in the following example:\n",
    "\n",
    "```\n",
    "In:  pd.DataFrame({\n",
    "         'A': pd.Series([1,2,3], index=[1,2,3]),\n",
    "         'B': pd.Series(['a', 'b', 'c'], index=[2, 5, 9])\n",
    "     })\n",
    "\n",
    "Out:      A    B\n",
    "     1  1.0  NaN\n",
    "     2  2.0    a\n",
    "     3  3.0  NaN\n",
    "     5  NaN    b\n",
    "     9  NaN    c\n",
    "```\n",
    "\n",
    "It is unknown at this time what algorithm each of the above methods uses. However, a hypothesized algorithm is provided in **ยง III.A**. Assuming this algorithm for all three methods, the time required for joining should scale as\n",
    "\n",
    "$\n",
    "O[a(L_\\text{left}-n_\\text{left}+L_\\text{right}-n_\\text{right}) + b(n_\\text{left}+n_\\text{right})]\\\\\n",
    "=O[a(L_\\text{left}+L_\\text{right}) + (b-a)(N_\\text{left}+N_\\text{right})]\n",
    "$\n",
    "\n",
    "where $L_\\text{[side]}$ is the length of the original dataset and $N_\\text{[side]}$ is the number of null values resulting on the given side. Constants $a$ and $b$ are unknown and represent the fact that shared indices and unshared indices might require different amounts of time to handle. Using $L$ as the single original dataset length and $n$ as the fraction of rows which are unshared, the expression becomes\n",
    "\n",
    "$ O[a(2L) + (a-b)(2nL)] $\n",
    "\n",
    "or\n",
    "\n",
    "(1) $\\qquad O[(\\alpha + \\beta n)L]$,\n",
    "\n",
    "where $\\alpha$ and $\\beta$ are unknown constants and the sign of $\\beta$ informs whether the join is sped up or slowed down by null values. From here, a linear model of the timing can be created as follows:\n",
    "\n",
    "(2) $\\qquad \\hat{t}(L) = t_0 + \\hat{m}L$,\n",
    "\n",
    "where $\\hat{m}$ itself is modeled linearly as follows:\n",
    "\n",
    "(3) $\\qquad \\hat{m}(n) = \\alpha + \\beta n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Notes\n",
    "\n",
    "### A. Notes about the \"length\" variable\n",
    "It is not known which \"length\" is related to the time required to join datasets. This would depend on the exact algorithm being used to compare indices. However, a reasonable algorithm for a full outer join might be like the following:\n",
    "1. Iterate over the left indices. For each index, check if it is present in the right dataset.\n",
    "    * If it is, include it in the resulting data frame. **Note to ignore this row when iterating over the right dataset.**\n",
    "    * If it is not, place a NaN value in the column representing the right dataset.\n",
    "2. Iterate over the right indices. **Skip previously used rows.** \n",
    "    * The remaining rows cannot be present in the left dataset since it was already iterated over. Therefore, for each row, place a *NaN* value in the colum representing the left dataset.\n",
    "\n",
    "### B. Notes about statistical methods\n",
    "\n",
    "*At this time, it is not known which statistical methods are appropriate to calculate the above models in a way that reflects their influence on each other. This will be researched after data is gathered.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Methods\n",
    "\n",
    "This notebook is runnable and involves random data. Therefore, it will give slightly different results each time. The full procedure takes between 30 minutes and an hour on my laptop for the cases described. If one wishes to test it with different cases, one can feel free to edit the **Initialize experimental data** section or tweak anything else desired.\n",
    "\n",
    "For greatest precision of results, it is best to stop other processes on one's computer to avoid interference with processing times. Alternatively, one can run the notebook alongside other processes to simulate a real-world situation.\n",
    "\n",
    "My results will also be provided at https://github.com/eanord4/random.git in CSV format. The **Choose data source** code block below allows the user to select between reading from a CSV and recalculating the experimental data.\n",
    "\n",
    "In the procedure below, functions are first defined to systematize the creation of datasets and the way joins were performed. For both the \"file\" and \"recalculate\" options, example datasets and joins are displayed for convenience after the function definitions.\n",
    "\n",
    "Each join is performed on two similar datasets of the same length. Values are randomly selected *floats* between 0 and 1. Each dataset consists of a single column of values and a set of integer indices upon which to perform the join. Each join is a full outer join on the indices.\n",
    "\n",
    "Next, experimental data are collected under each case described below. For each combination of $L$ and $n$, six sets of trials are performed--one in each possible order of the three join methods. The order of the six sets of trials is randomized before collection of data (but kept constant throughout collection). In each trial, the join is performed three times within the *timeit* function.\n",
    "\n",
    "Once collected, all trials are analyzed using *pandas* and *matplotlib* plotting methods.\n",
    "\n",
    "### A. Cases\n",
    "* data frame length ($L$) = 10<sup>$p$</sup> where $p$ ranges from 1 to 7 in increments of 1\n",
    "    * *It is not yet clear which \"length\" is related to the time required for the join. See notes below.*\n",
    "* number of unshared rows (resulting in null values) ($n$) = 10% to 90% in increments of 10%\n",
    "* join methods used: *pandas.merge*, *pandas.DataFrame.merge*, and *pandas.DataFrame.\\__new\\__*\n",
    "\n",
    "### B. Dependencies\n",
    "The following Python packages were used:\n",
    "* *pandas* 0.25.3\n",
    "* *matplotlib* 3.1.2\n",
    "* *scikit-learn* 0.19.1\n",
    "* *random*\n",
    "* *timeit*\n",
    "* *math*\n",
    "* *itertools*\n",
    "\n",
    "### C. Statistical methods\n",
    "See **ยง III.B**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Choose data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose data source (type 0 or 1)...\n",
      "    \"from file\" = 0\n",
      "    \"recalculate\" = 1\n",
      "Input: 0\n",
      "Enter CSV path to retrieve data...\n",
      "    or press <Enter> for default: \"pandas_join_comparison_results.csv\"\n",
      "Input: \n"
     ]
    }
   ],
   "source": [
    "# Determine data source\n",
    "data_source_choices = ['from file', 'recalculate']\n",
    "data_source = data_source_choices[int(input('''\\\n",
    "Choose data source (type 0 or 1)...\n",
    "    \"from file\" = 0\n",
    "    \"recalculate\" = 1\n",
    "Input: \\\n",
    "'''))]\n",
    "\n",
    "# Establish file path\n",
    "\n",
    "default_csv_path = 'pandas_join_comparison_results.csv'  # default CSV path\n",
    "action = 'save' if data_source == 'recalculate' else 'retrieve'\n",
    "user_input = input(f'''\\\n",
    "Enter CSV path to {action} data...\n",
    "    or press <Enter> for default: \"{default_csv_path}\"\n",
    "Input: \\\n",
    "''')\n",
    "_csv_path = user_input if user_input.split() else default_csv_path\n",
    "\n",
    "if data_source == 'recalculate':\n",
    "    output_csv_path = _csv_path\n",
    "else:\n",
    "    input_csv_path = _csv_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import timeit\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import random as rm\n",
    "\n",
    "if data_source == 'recalculate':\n",
    "    import math\n",
    "    import itertools as it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define useful functions to produce datasets and joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_merge(left_series, right_series):\n",
    "    '''merge the datasets using `pd.merge`'''\n",
    "\n",
    "    return pd.merge(left_series, right_series, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "def df_merge(left_df, right_series):\n",
    "    '''merge the datasets using `pd.DataFrame.merge`; requires left dataset to be a data frame'''\n",
    "\n",
    "    return left_df.merge(right_series, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "def new_df_join(left_series, right_series):\n",
    "    '''merge the datasets by calling `pd.DataFrame`'''\n",
    "\n",
    "    return pd.DataFrame({'LEFT': left_series, 'RIGHT': right_series})\n",
    "\n",
    "def datasets(L, n):\n",
    "    '''generate two series of the specified length and unshared fraction of rows'''\n",
    "\n",
    "    N_unshared = int(n * L)  # number of unshared rows in each dataset. The total number of null values after joining will be double.\n",
    "    length_range = range(L)\n",
    "    all_indices = range(L + N_unshared)\n",
    "\n",
    "    # get values\n",
    "    left_data = [rm.random() for i in length_range]\n",
    "    right_data = [rm.random() for i in length_range]\n",
    "\n",
    "    # get left indices\n",
    "    left_indices = sorted(rm.sample(all_indices, L))\n",
    "    remaining = set(all_indices).difference(left_indices)\n",
    "\n",
    "    # get right indices\n",
    "    right_indices = rm.sample(left_indices, L - N_unshared)  # shared indices\n",
    "    right_indices += rm.sample(remaining, N_unshared)  # unshared indices\n",
    "    right_indices = sorted(right_indices)  # order of shared and unshared will be random\n",
    "\n",
    "    # construct datasets as series\n",
    "    left_series = pd.Series(left_data, index=left_indices, name='LEFT')\n",
    "    right_series = pd.Series(right_data, index=right_indices, name='RIGHT')\n",
    "\n",
    "    return left_series, right_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Test the functions and display example datasets and join results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. Get example datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 10\n",
    "n = .5\n",
    "left_example, right_example = datasets(L, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. Display left example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     0.813005\n",
       "4     0.638027\n",
       "5     0.837428\n",
       "7     0.203164\n",
       "9     0.773284\n",
       "10    0.782185\n",
       "11    0.828333\n",
       "12    0.129063\n",
       "13    0.034586\n",
       "14    0.598717\n",
       "Name: LEFT, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iii. Display right example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.568928\n",
       "2     0.260085\n",
       "3     0.488607\n",
       "5     0.609170\n",
       "6     0.934339\n",
       "8     0.863590\n",
       "9     0.401285\n",
       "10    0.246014\n",
       "11    0.109273\n",
       "13    0.371681\n",
       "Name: RIGHT, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "right_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### iv. Display example join using pandas.merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LEFT</th>\n",
       "      <th>RIGHT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.568928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.813005</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.260085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.488607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.638027</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.837428</td>\n",
       "      <td>0.609170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.934339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203164</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.863590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.773284</td>\n",
       "      <td>0.401285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.782185</td>\n",
       "      <td>0.246014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.828333</td>\n",
       "      <td>0.109273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.129063</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.371681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.598717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        LEFT     RIGHT\n",
       "0        NaN  0.568928\n",
       "1   0.813005       NaN\n",
       "2        NaN  0.260085\n",
       "3        NaN  0.488607\n",
       "4   0.638027       NaN\n",
       "5   0.837428  0.609170\n",
       "6        NaN  0.934339\n",
       "7   0.203164       NaN\n",
       "8        NaN  0.863590\n",
       "9   0.773284  0.401285\n",
       "10  0.782185  0.246014\n",
       "11  0.828333  0.109273\n",
       "12  0.129063       NaN\n",
       "13  0.034586  0.371681\n",
       "14  0.598717       NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_merge_result = pd_merge(left_example, right_example)\n",
    "pd_merge_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### v. Show that all ways of joining yield the same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`pd.merge` result same as `pd.DataFrame.merge`?\n",
      "---------------------------------------------------\n",
      "True\n",
      "\n",
      "`pd.merge` result same as `pd.DataFrame.__new__`?\n",
      "---------------------------------------------------\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('`pd.merge` result same as `pd.DataFrame.merge`?')\n",
    "print('---------------------------------------------------')\n",
    "print(all( pd_merge_result == df_merge(left_example.to_frame(), right_example) ))\n",
    "print()\n",
    "\n",
    "print('`pd.merge` result same as `pd.DataFrame.__new__`?')\n",
    "print('---------------------------------------------------')\n",
    "print(all( pd_merge_result == new_df_join(left_example, right_example) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. If recalculating: initialize experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'recalculate':\n",
    "    \n",
    "    # Cases to be tried\n",
    "    L_cases = [10, 10 ** 2, 10 ** 3, 10 ** 4, 10 ** 5, 10 ** 6, 10 ** 7]\n",
    "    n_cases = [.1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "    join_names = ['pd.merge', 'pd.DataFrame.merge', 'pd.DataFrame.__new__']\n",
    "    join_funcs = [pd_merge, df_merge, new_df_join]\n",
    "\n",
    "    # Additional definitions\n",
    "    n_as_pcts = [f'{100 * n:.1f}%' for n in n_cases]\n",
    "    join_cases = list(zip(join_names, join_funcs))\n",
    "    join_permutations = list(it.permutations(join_cases))\n",
    "    num_methods = len(join_cases)\n",
    "    num_trials = len(join_permutations)\n",
    "    num_to_time = 3  # repetitions within `timeit`\n",
    "\n",
    "    # Initialize\n",
    "    times = pd.DataFrame(\n",
    "\n",
    "        columns=join_names,\n",
    "\n",
    "        index=pd.MultiIndex.from_product(\n",
    "            [L_cases, n_as_pcts, range(num_trials)],\n",
    "            names=['L', 'n', 'Trial']\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "    # Show structure of experimental data\n",
    "    times.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Obtain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if data_source == 'recalculate':\n",
    "\n",
    "    # Randomize order of sets of trials\n",
    "\n",
    "    randomized_trials = rm.sample(join_permutations, num_trials)\n",
    "\n",
    "\n",
    "    # Collect data\n",
    "\n",
    "    for L in L_cases:\n",
    "\n",
    "        print(f'L = {L:,}...')\n",
    "\n",
    "        for n, n_as_pct in zip(n_cases, n_as_pcts):\n",
    "\n",
    "            print(f'\\tn = {n_as_pct}...')\n",
    "\n",
    "            for trial_num, permutation in enumerate(randomized_trials):\n",
    "                print(f'\\t\\tTrial #{trial_num}...')\n",
    "\n",
    "                for join_name, join_func in permutation:\n",
    "\n",
    "                    print(f'\\t\\t\\t{join_name}...')\n",
    "\n",
    "                    times.loc[(L, n_as_pct, trial_num), join_name] = timeit(\n",
    "\n",
    "                        stmt='join_func(left_data, right_data)',\n",
    "\n",
    "                        setup='left_data, right_data = datasets(L, n)'\n",
    "                        + '\\nleft_data = left_data.to_frame()'\n",
    "                        * (join_name == 'pd.DataFrame.merge'),\n",
    "\n",
    "                        number=num_to_time,\n",
    "\n",
    "                        globals={\n",
    "                            'join_func': join_func,\n",
    "                            'datasets': datasets,\n",
    "                            'L': L,\n",
    "                            'n': n,\n",
    "                        }\n",
    "\n",
    "                    ) / num_to_time\n",
    "\n",
    "            print()\n",
    "\n",
    "        print()\n",
    "        \n",
    "        \n",
    "    # Save data to new file\n",
    "\n",
    "    times.to_csv(output_csv_path)\n",
    "\n",
    "else:\n",
    "    times = pd.read_csv(input_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Preview data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L</th>\n",
       "      <th>n</th>\n",
       "      <th>Trial</th>\n",
       "      <th>pd.merge</th>\n",
       "      <th>pd.DataFrame.merge</th>\n",
       "      <th>pd.DataFrame.__new__</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.001651</td>\n",
       "      <td>0.001046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.001229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001624</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.001025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.000892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>10.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.000911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>10000000</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>1</td>\n",
       "      <td>2.092372</td>\n",
       "      <td>2.046584</td>\n",
       "      <td>3.797931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>10000000</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>2</td>\n",
       "      <td>2.062062</td>\n",
       "      <td>1.998068</td>\n",
       "      <td>3.781070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>10000000</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>3</td>\n",
       "      <td>2.131902</td>\n",
       "      <td>2.014894</td>\n",
       "      <td>3.755780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>10000000</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>4</td>\n",
       "      <td>2.084182</td>\n",
       "      <td>1.981168</td>\n",
       "      <td>3.675436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>10000000</td>\n",
       "      <td>90.0%</td>\n",
       "      <td>5</td>\n",
       "      <td>2.076571</td>\n",
       "      <td>2.010079</td>\n",
       "      <td>3.923985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows ร 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            L      n  Trial  pd.merge  pd.DataFrame.merge  \\\n",
       "0          10  10.0%      0  0.001852            0.001651   \n",
       "1          10  10.0%      1  0.001687            0.001327   \n",
       "2          10  10.0%      2  0.001624            0.001237   \n",
       "3          10  10.0%      3  0.001575            0.001379   \n",
       "4          10  10.0%      4  0.001961            0.001288   \n",
       "..        ...    ...    ...       ...                 ...   \n",
       "373  10000000  90.0%      1  2.092372            2.046584   \n",
       "374  10000000  90.0%      2  2.062062            1.998068   \n",
       "375  10000000  90.0%      3  2.131902            2.014894   \n",
       "376  10000000  90.0%      4  2.084182            1.981168   \n",
       "377  10000000  90.0%      5  2.076571            2.010079   \n",
       "\n",
       "     pd.DataFrame.__new__  \n",
       "0                0.001046  \n",
       "1                0.001229  \n",
       "2                0.001025  \n",
       "3                0.000892  \n",
       "4                0.000911  \n",
       "..                    ...  \n",
       "373              3.797931  \n",
       "374              3.781070  \n",
       "375              3.755780  \n",
       "376              3.675436  \n",
       "377              3.923985  \n",
       "\n",
       "[378 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Plot time vs. length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# times.xs(.5, level=1)\\\n",
    "# .apply(lambda s: s.apply(math.log))\\\n",
    "# .reset_index(level=0)\\\n",
    "# .plot.line(x='L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EAN general kernel spec",
   "language": "python",
   "name": "gen-kernelspec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
